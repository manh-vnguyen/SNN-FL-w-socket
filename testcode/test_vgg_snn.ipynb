{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>> VGG 9 >>>>>>>>>>>>>>>>>>>>>>\n",
      "***** time step per batchnorm\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "\n",
    "import vgg_spiking_bntt as snn_models_bntt\n",
    "\n",
    "DATA_PATH='/tmp/data/cifar10'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_args = {'num_cls': 100, 'timesteps': 20}\n",
    "net = snn_models_bntt.SNN_VGG9_BNTT(**model_args).cuda()\n",
    "\n",
    "trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "dataset_train = datasets.CIFAR10(DATA_PATH, train=True, download=True, transform=trans_cifar)\n",
    "dataset_test = datasets.CIFAR10(DATA_PATH, train=False, download=True, transform=trans_cifar)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "trainloader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001, weight_decay = 0.0001, amsgrad = True)\n",
    "\n",
    "batch_loss = []\n",
    "for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "    net.zero_grad()\n",
    "    log_probs = net(images)\n",
    "    loss = loss_func(log_probs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # if batch_idx % 10 == 0:\n",
    "    #     print('Update Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "    #         iter, batch_idx * len(images), len(trainloader.dataset),\n",
    "    #                 100. * batch_idx / len(trainloader), loss.item()))\n",
    "    # batch_loss.append(loss.item())\n",
    "    # if (batch_idx + 1) % BATCH_SIZE == 0:\n",
    "    #     thresholds = []\n",
    "    #     for value in net.module.threshold.values():\n",
    "    #         thresholds = thresholds + [round(value.item(), 2)]\n",
    "    #     print('Epoch: {}, batch {}, threshold {}, leak {}, timesteps {}'.format(iter, batch_idx + 1, thresholds, net.module.leak.item(), net.module.timesteps))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
